{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3df85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "__author__     = 'Radu Revutchi'\n",
    "__email__      = 'radurevutchi@cmu.edu'\n",
    "__date__       = '2020'\n",
    "\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Sets GPU to use\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "#############\n",
    "# Terminology\n",
    "# AV = Action Vector\n",
    "# AE = Audio Embedding\n",
    "#############\n",
    "\n",
    "\n",
    "'''\n",
    "Preprocessing Description\n",
    "\n",
    "1) Imports AEs and AVs\n",
    "2) Converts each AE from shape (46, 6144) to shape (6144)\n",
    "... by computing the mean across each of the 46 timestamps\n",
    "3) Finds the corresponding AV [shape (20)] for each AE\n",
    "4) Stacks the AV to the AE to create a single feature of shape (6164)\n",
    "'''\n",
    "def preprocessData(av_filename, ae_filename):\n",
    "\n",
    "\t#Load metadata and AV data\n",
    "\tav_training_data = pd.read_csv(av_filename) # AV CSV\n",
    "\tcategories = av_training_data['category']\n",
    "\taudio_files = av_training_data['filename']\n",
    "\tav_training_data = av_training_data.drop(columns = ['filename','fold','target','category'])\n",
    "\tx_actionvectors = av_training_data.to_numpy(dtype='float') # AV data\n",
    "\n",
    "\n",
    "\t# Converts string class-names to numerical(integer) classes\n",
    "\tle = LabelEncoder()\n",
    "\tle.fit(categories)\n",
    "\ty_train = le.transform(categories)\n",
    "\n",
    "\t# One-Hot Encodes each integer class\n",
    "\tlb = LabelBinarizer()\n",
    "\tlb.fit(y_train)\n",
    "\ty_train = lb.transform(y_train)\n",
    "\n",
    "\tembeddings_dict = {} # Audio filename to embedding mapping\n",
    "\traw_embeddings = np.load(ae_filename, allow_pickle=True) # Imports AEs\n",
    "\n",
    "\t# Iterates through AEs\n",
    "\t# Creates filename to embedding table\n",
    "\t# Takes average across time for each embedding\n",
    "\tfor i in range(len(raw_embeddings)):\n",
    "\t\tfname = raw_embeddings[i][0]\n",
    "\t\tembedding = raw_embeddings[i][1]\n",
    "\t\tembedding_mean = embedding.mean(axis=0)# Takes average across timesteps\n",
    "\t\tassert(len(embedding_mean) == 6144) #AE dimension\n",
    "\t\tembeddings_dict[fname] = embedding_mean \n",
    "\n",
    "\t# Concatenates corresponding AV to each AE\n",
    "\tx_train_stacked = []\n",
    "\tfor i in range(len(audio_files)):\n",
    "\t\tfname = audio_files[i] # Audio filename\n",
    "\t\tav = np.array(x_actionvectors[i]) #corresponding AV\n",
    "\t\tembedding = embeddings_dict[fname]\n",
    "\t\tx_train_stacked.append(np.concatenate((embedding,av)))\n",
    "\t\t\n",
    "\t# Converts to Numpy Array\n",
    "\tx_train_stacked = np.array(x_train_stacked)\n",
    "\tassert(len(x_train_stacked) == 2000) # total files in ESC50\n",
    "\tassert(len(x_train_stacked[0]) == 6164) #AE 6144x1 + AV 20x1\n",
    "\treturn (x_train_stacked, y_train)\n",
    "\n",
    "\n",
    "def train_test_model(all_x_train, all_y_train):\n",
    "\t# Will collect statistics\n",
    "\tcf_report = []\n",
    "\taccuracy = []\n",
    "\n",
    "\t# Iterate over 5 folds\n",
    "\t# Folds designated by ESC50 dataset\n",
    "\tfor fold in range(5):\n",
    "\t\tprint('')\n",
    "\n",
    "\t\t# Splits data into 80/20 train/test sections based on predefined fold numbers\n",
    "\t\tx_train = np.concatenate((all_x_train[0:fold*400],\n",
    "\t\t\t\t\t\t\t\tall_x_train[(fold+1)*400:]))\n",
    "\t\tx_test = all_x_train[fold*400:(fold+1)*400]\n",
    "\t\ty_train = np.concatenate((all_y_train[0:fold*400],\n",
    "\t\t\t\t\t\t\t\tall_y_train[(fold+1)*400:]))\n",
    "\t\ty_test = all_y_train[fold*400:(fold+1)*400]\n",
    "\n",
    "\t\t# Normalize the data\n",
    "\t\tnormalize = Normalizer(norm='l2').fit(x_train)\n",
    "\t\tx_train = normalize.transform(x_train)\n",
    "\t\tx_test = normalize.transform(x_test)\n",
    "\t\t#Scaling improved performance in some cases, referred to the paper\n",
    "# \t\tscaler = StandardScaler().fit(x_train) \n",
    "# \t\tx_train = scaler.transform(x_train)\n",
    "# \t\tx_test = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "\t\t# Setting up model structure\n",
    "\t\tmodel = tf.keras.Sequential()\n",
    "\t\tmodel.add(tf.keras.layers.Dense(units=800,input_dim=len(x_train[0])))\n",
    "\t\tmodel.add(tf.keras.layers.BatchNormalization())\n",
    "\t\tmodel.add(tf.keras.layers.Activation('tanh'))\n",
    "\t\tmodel.add(tf.keras.layers.Dropout(0.5))\n",
    "\t\tmodel.add(tf.keras.layers.Dense(units=500))\n",
    "\t\tmodel.add(tf.keras.layers.BatchNormalization())\n",
    "\t\tmodel.add(tf.keras.layers.Activation('tanh'))\n",
    "\t\tmodel.add(tf.keras.layers.Dropout(0.5))\n",
    "\t\tmodel.add(tf.keras.layers.Dense(units=200))\n",
    "\t\tmodel.add(tf.keras.layers.BatchNormalization())\n",
    "\t\tmodel.add(tf.keras.layers.Activation('tanh'))\n",
    "\t\tmodel.add(tf.keras.layers.Dropout(0.5))\n",
    "\t\tmodel.add(tf.keras.layers.Dense(units=50, activation='softmax'))\n",
    "\n",
    "\t\topt = tf.keras.optimizers.SGD(lr=0.008)\n",
    "\t\tmodel.compile(loss='categorical_crossentropy',\n",
    "\t\t\t\t\t\t\toptimizer=opt,\n",
    "\t\t\t\t\t\t\tmetrics=['accuracy'])\n",
    "\t\tmodel.fit(x_train,y_train,epochs=100,batch_size=32)# Increasing the number of epochs may improve performance\n",
    "\n",
    "\t\t\n",
    "\t\t_, test_accuracy = model.evaluate(x_test, y_test)\n",
    "\t\taccuracy.append(test_accuracy)\n",
    "\t\tprint(accuracy)\n",
    "\n",
    "\t\t# Setting up classification_report\n",
    "\t\tY_test = np.argmax(y_test,axis=1)\n",
    "\t\ty_pred = model.predict_classes(x_test)\n",
    "\t\tcf_report.append(classification_report(Y_test, y_pred))\n",
    "\n",
    "\n",
    "\t# Prints a Classification Report for each fold\n",
    "\tprint(\"Classification Reports\")\n",
    "\tfor r in cf_report:\n",
    "\t\tprint(r)\n",
    "\n",
    "\t# Prints accuracy for each fold\n",
    "\tprint(\"Accuracy per FOLD:\")\n",
    "\tfor a in range(len(accuracy)):\n",
    "\t\tprint(\"Fold \" + str(a) + \" Accuracy:\", accuracy[a])\n",
    "\n",
    "\t# Prints aggregate statistics\n",
    "\tprint('')\n",
    "\tprint(\"Avg Accuracy:\", sum(accuracy) / 5)\n",
    "\tprint(\"Standard Deviation:\", np.std(accuracy))\n",
    "\n",
    "\n",
    "# Imports, modifies, and stacks AE to AV features\n",
    "av_filename = 'action_vectors/actionvector_one_per_audiofile_sum.csv'\n",
    "ae_filename = 'ESC-50_openl3_music_mel256_6144.npy' # This file can be created with the script \"compute_audio_embeddings.py\"\n",
    "(all_x_train, all_y_train) = preprocessData(av_filename, ae_filename)\n",
    "\n",
    "# Runs training on model\n",
    "train_test_model(all_x_train, all_y_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
